{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import datetime as dt\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af6cd6-c3cc-4d12-8b04-a4178d63939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_val_1D_char(ds,varname,new_val):\n",
    "    var=ds.variables[varname]\n",
    "    old_val=var[:].tobytes().decode().strip()\n",
    "    \n",
    "    print(\"Modifying \",varname,\" from \", old_val,\" to \",new_val)\n",
    "\n",
    "    new_array=np.chararray(var.shape)\n",
    "    new_array[:]=\" \" \n",
    "    for i in range(len(new_val)):\n",
    "        if len(var.shape)==2:\n",
    "            new_array[0,i]=new_val[i]\n",
    "        else:\n",
    "            new_array[i]=new_val[i]\n",
    "            \n",
    "\n",
    "    var[:]=new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5a112-91d5-4a90-98f6-dad53af8582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_val_2D_char(ds,varname,dim_level,new_val):\n",
    "    var=ds.variables[varname]\n",
    "    old_val=var[dim_level,:].tobytes().decode().strip()\n",
    "    print(\"Modifying \",varname,\" for dim_level \", dim_level, \"from \", old_val,\" to \",new_val)\n",
    "\n",
    "    new_type_array=np.chararray(var[dim_level,:].shape)\n",
    "    new_type_array[:]=\" \" \n",
    "    for i in range(len(new_val)):\n",
    "        new_type_array[i]=new_val[i]\n",
    "    var[dim_level,:]=new_type_array[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7a1cf-ee90-41c3-824d-2a6cafe2c6e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dac=\"coriolis\"\n",
    "liste_wmos=['1901351']\n",
    "\n",
    "file_prefix='nemo_0100'\n",
    "in_positions_file=\"C:/Users/ddobler/Documents/NEMO/NEMO_profile_files/co010103v1/parsed_pos_dot_profile/pos_dot_profile_\"+file_prefix+\".csv\"\n",
    "print(in_positions_file,os.path.exists(in_positions_file))\n",
    "if os.path.exists(in_positions_file):\n",
    "    coordinates = pd.read_csv(in_positions_file,sep=\";\")\n",
    "else:\n",
    "    print(in_positions_file, \" does not exist, WARNING !\")\n",
    "CYCLE_NUMBER=(np.array(coordinates.CYCLE)).astype('int')\n",
    "LATITUDE=np.array(coordinates.LATITUDE)\n",
    "LONGITUDE=np.array(coordinates.LONGITUDE)\n",
    "JULD=np.array(coordinates.JULD,dtype=np.datetime64)\n",
    "JULD=((JULD-np.datetime64(\"1950-01-01T00:00:00\")).astype('int'))/86400\n",
    "JULD_QC=np.array(coordinates.JULD_QC)\n",
    "JULD_LOCATION=JULD[:]\n",
    "POSITION_QC=np.array(coordinates.POSITION_QC)\n",
    "\n",
    "\n",
    "in_dc_reference_file=\"C:/Users/ddobler/Documents/NEMO/NEMO_profile_files/co010103v1/p_coriolis_db_reference/dc_reference_for_\"+file_prefix+\".csv\"\n",
    "print(\"loading dc_reference - extracted beforehand from coriolis db \")\n",
    "print(in_dc_reference_file,os.path.exists(in_dc_reference_file))\n",
    "if os.path.exists(in_dc_reference_file):\n",
    "    dc_reference_from_coriolis = pd.read_csv(in_dc_reference_file,sep=\";\",dtype={'wmo': str, 'cycle': int, 'dir': str, 'dc_reference': str})\n",
    "else:\n",
    "    print(in_dc_reference_file, \" does not exist, WARNING !\")\n",
    "\n",
    "cycle_start=61\n",
    "cycle_end=69\n",
    "data_mode_file=\"D\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c4e6e5-cebe-4db3-b685-87d4c2230403",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrk_dir=\"C:/Users/ddobler/Documents/08_DD_scripts/01_Scripts_Metadata_and_Data_Update/ProfData_WorkDir/lot_002/\"\n",
    "\n",
    "#for wmo in list_wmo:\n",
    "for iwmo in range(len(liste_wmos)):\n",
    "#for iwmo in range(3):\n",
    "\n",
    "    wmo=liste_wmos[iwmo]\n",
    "    #nnn_val=liste_val[iwmo]\n",
    "    #nnn_val2=liste_val2[iwmo]\n",
    "    #nnn_val3=liste_val3[iwmo]\n",
    "    #nnn_val4=liste_val4[iwmo]\n",
    "    #nnn_val5=liste_val5[iwmo]\n",
    "\n",
    "    history_update_text='updated by D.Dobler (Euro-Argo ERIC) for a JULD error of approx. 1day'\n",
    "\n",
    "    # Select wmo to treat\n",
    "    #wmo=\"6900203\"\n",
    "    print(\"\\n\\n---------------------------\")\n",
    "    print(\"Treating wmo \",wmo)\n",
    "\n",
    "\n",
    "    for icycle in range(cycle_start,cycle_end+1):\n",
    "    # select modifications to perform\n",
    "\n",
    "        print(\"extracting dc_reference for the current cycle\")\n",
    "        l_dc_ref=\" \"\n",
    "        try:\n",
    "            dc_reference_from_coriolis_icycle=dc_reference_from_coriolis.loc[(dc_reference_from_coriolis['cycle'] == icycle) & \n",
    "                                                                             (dc_reference_from_coriolis['dir'] == 'A') & \n",
    "                                                                             (dc_reference_from_coriolis['wmo'] == wmo)]\n",
    "            l_dc_ref=str(np.array(dc_reference_from_coriolis_icycle['dc_reference'])[0])\n",
    "        except:\n",
    "            print(\"No DC_REFERENCE found for this cycle\")\n",
    "        print('DC_REFERENCE=',l_dc_ref)\n",
    "\n",
    "        if icycle == 15:\n",
    "            continue\n",
    "\n",
    "        i_new_juld                    = 0\n",
    "        new_juld = JULD[np.where(CYCLE_NUMBER==icycle)]\n",
    "    \n",
    "        i_new_PI_NAME                 = 0\n",
    "        new_PI_NAME=\"Birgit KLEIN\"\n",
    "    \n",
    "        i_new_pf_type                 = 0\n",
    "        new_pf_type='NEMO'\n",
    "    \n",
    "        i_new_positioning_system_1    = 0\n",
    "        new_positioning_system_1='GPS'\n",
    "    \n",
    "        i_new_float_sn                = 0\n",
    "        new_float_sn=\"tutu\"\n",
    "\n",
    "        i_new_dc_reference            = 1\n",
    "        new_dc_reference  = l_dc_ref\n",
    "    \n",
    "        i_history_update_3_1          = 0\n",
    "    \n",
    "        i_ftp_from_ifremer            = 1\n",
    "        #where to save\n",
    "        \n",
    "        if not os.path.exists(wrk_dir):\n",
    "            os.mkdir(wrk_dir)\n",
    "        file_to_update=data_mode_file + wmo + \"_{0:03d}.nc\".format(icycle)\n",
    "        OUT_FILE=wrk_dir + file_to_update\n",
    "        print(OUT_FILE)\n",
    "        \n",
    "     \n",
    "        # where to get \n",
    "        if i_ftp_from_ifremer:\n",
    "            print(\"Getting file from data-argo.ifremer.fr\")\n",
    "            URL = \"https://data-argo.ifremer.fr/dac/\"+dac+\"/\"+wmo+\"/profiles/\"+data_mode_file + wmo + \"_{0:03d}.nc\".format(icycle)\n",
    "            #URL = \"https://data-argo.ifremer.fr/dac/\"+dac+\"/\"+wmo+\"/profiles/\"+ file_to_update\n",
    "            print(URL)\n",
    "            # commands\n",
    "            response = requests.get(URL)\n",
    "            open(OUT_FILE, \"wb\").write(response.content)\n",
    "        else:\n",
    "            print(\"Getting file from local directory\")\n",
    "            #IN_FILE=\"C:/Users/ddobler/Documents/09_Scripts_WD/lot_014_deleted_level_in/\" + wmo + \"_meta.nc\"\n",
    "            shutil.copyfile(IN_FILE,OUT_FILE)\n",
    "    \n",
    "        #print(\"Making changes for wmo \",wmo)\n",
    "    \n",
    "        ds=Dataset(OUT_FILE,'a')\n",
    "    \n",
    "        # update the global attribute history:\n",
    "        date_courante=dt.datetime.now(dt.timezone.utc)\n",
    "        date_courante_str=date_courante.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        #lhistory=date_courante_str+ ' creation; '+date_courante_str+' last update (coriolis float real time data processing)'\n",
    "    \n",
    "    \n",
    "        if i_new_positioning_system_1:\n",
    "            change_val_2D_char(ds,\"POSITIONING_SYSTEM\",0,new_positioning_system_1)\n",
    "    \n",
    "        if i_history_update_3_1:\n",
    "            print(\"Modifying global attribute section\")\n",
    "            ds.title = \"Argo float vertical profile\"\n",
    "            ds.institution = \"CORIOLIS\"\n",
    "            ds.source = \"Argo float\"\n",
    "            ds.history = lhistory\n",
    "            ds.references = \"http://www.argodatamgt.org/Documentation\" ;\n",
    "            ds.user_manual_version = \"3.1\"\n",
    "            ds.Conventions = \"Argo-3.1 CF-1.6\"\n",
    "            #new_ds.decoder_version = \"\"\n",
    "            ds.featureType = \"trajectoryProfile\"\n",
    "    \n",
    "    \n",
    "        if i_new_juld:\n",
    "            l_juld=ds.variables[\"JULD\"]\n",
    "            print(\"Modifying JULD from \", l_juld[:],\" to \",new_juld)\n",
    "            l_juld[:]=new_juld\n",
    "            l_juld_loc=ds.variables[\"JULD_LOCATION\"]\n",
    "            print(\"Modifying JULD_LOCATION from \", l_juld_loc[:],\" to \",new_juld)\n",
    "            l_juld_loc[:]=new_juld\n",
    "            \n",
    "            \n",
    "        if i_new_float_sn: change_val_1D_char(ds,\"FLOAT_SERIAL_NO\",new_float_sn)\n",
    "        if i_new_dc_reference: \n",
    "            print(new_dc_reference)\n",
    "            \n",
    "            change_val_1D_char(ds,\"DC_REFERENCE\",new_dc_reference)\n",
    "                    \n",
    "        if i_new_pf_type:\n",
    "            try:\n",
    "                varname=\"PLATFORM_TYPE\"\n",
    "                var=ds.variables[varname]\n",
    "            except:\n",
    "                varname=\"PLATFORM_MODEL\"\n",
    "                var=ds.variables[varname]\n",
    "            change_val_1D_char(ds,varname,new_pf_type)     \n",
    "            \n",
    "        \n",
    "        if i_new_PI_NAME: change_val_1D_char(ds,\"PI_NAME\",new_PI_NAME)\n",
    "    \n",
    "        \n",
    "        \n",
    "        print(\"\\n Updating history global attribute\")\n",
    "    \n",
    "        tmp=str(ds.variables[\"DATE_CREATION\"][:].tobytes(),'utf-8')\n",
    "        record_date_creation=tmp[:4]+\"-\"+tmp[4:6]+\"-\"+tmp[6:8]+\"T\"+tmp[8:10]+\":\"+tmp[10:12]+\":\"+tmp[12:14]+\"Z\"\n",
    "        #print(record_date_creation)\n",
    "    \n",
    "    \n",
    "        # update the global attribute history:\n",
    "        date_courante=dt.datetime.now(dt.timezone.utc)\n",
    "        date_courante_str=date_courante.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        lhistory=record_date_creation+ ' creation; '+date_courante_str + ' ' + history_update_text \n",
    "        #lhistory=record_date_creation+ ' creation; '+date_courante_str+' updated'\n",
    "        try:\n",
    "            print(\"Old history global attr: \",ds.history)\n",
    "        except:\n",
    "            print(\"Old history global attr did not exist\")\n",
    "        ds.history = lhistory\n",
    "        print(\"New history global attr: \",ds.history)\n",
    "    \n",
    "        print(\"Updating DATE_UPDATE\")\n",
    "        varname=\"DATE_UPDATE\"\n",
    "        new_val=date_courante.strftime(\"%Y%m%d%H%M%S\")\n",
    "        change_val_1D_char(ds,varname,new_val)\n",
    "\n",
    "    \n",
    "        ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52018ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"wmo=\",wmo)\n",
    "\n",
    "# check step\n",
    "ds=Dataset(OUT_FILE,'r')\n",
    "SENSOR_TYPE=ds.variables[\"SENSOR\"]\n",
    "SENSOR_MAKER=ds.variables[\"SENSOR_MAKER\"]\n",
    "SENSOR_MODEL=ds.variables[\"SENSOR_MODEL\"]\n",
    "SENSOR_SN=ds.variables[\"SENSOR_SERIAL_NO\"]\n",
    "DATE_UPDATE=ds.variables[\"DATE_UPDATE\"]\n",
    "LAUNCH_LATITUDE=ds.variables[\"LAUNCH_LATITUDE\"]\n",
    "LAUNCH_LONGITUDE=ds.variables[\"LAUNCH_LONGITUDE\"]\n",
    "LAUNCH_DATE=ds.variables[\"LAUNCH_DATE\"]\n",
    "START_DATE=ds.variables[\"START_DATE\"]\n",
    "PLATFORM_MAKER=ds.variables[\"PLATFORM_MAKER\"]\n",
    "\n",
    "hh=ds.history\n",
    "\n",
    "print(\"\\n--global attribute history\")\n",
    "print(hh)\n",
    "\n",
    "print(\"\\n--PLATFORM_MAKER:\")\n",
    "print(PLATFORM_MAKER[:].tobytes().decode().strip())\n",
    "\n",
    "print(\"\\n--SENSOR_TYPE:\")\n",
    "print(SENSOR_TYPE[:,:].tobytes().decode().strip())\n",
    "\n",
    "print(\"\\n--SENSOR_MAKER:\")\n",
    "print(SENSOR_MAKER[:,:].tobytes().decode().strip())\n",
    "\n",
    "print(\"\\n--SENSOR_MODEL:\")\n",
    "print(SENSOR_MODEL[:,:].tobytes().decode().strip())\n",
    "\n",
    "print(\"\\n--SENSOR_SN:\")\n",
    "print(SENSOR_SN[:,:].tobytes().decode().strip())\n",
    "\n",
    "print(\"\\n--LAUNCH_LONGITUDE:\")\n",
    "print(LAUNCH_LONGITUDE[:])\n",
    "\n",
    "print(\"\\n--LAUNCH_LATITUDE:\")\n",
    "print(LAUNCH_LATITUDE[:])\n",
    "\n",
    "print(\"\\n--LAUNCH_DATE:\")\n",
    "print(LAUNCH_DATE[:].tobytes().decode().strip())\n",
    "\n",
    "print(\"\\n--START_DATE:\")\n",
    "print(START_DATE[:].tobytes().decode().strip())\n",
    "\n",
    "print(\"\\n--DATE_UPDATE:\")\n",
    "print(DATE_UPDATE[:].tobytes().decode().strip())\n",
    "\n",
    "ds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
